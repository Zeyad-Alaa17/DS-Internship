{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:01.111798Z",
     "iopub.status.busy": "2021-08-29T17:57:01.111426Z",
     "iopub.status.idle": "2021-08-29T17:57:03.296113Z",
     "shell.execute_reply": "2021-08-29T17:57:03.295309Z",
     "shell.execute_reply.started": "2021-08-29T17:57:01.111705Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Data Visualizations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(font_scale= 2)\n",
    "\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torchvision import transforms, datasets, models\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:03.297772Z",
     "iopub.status.busy": "2021-08-29T17:57:03.297456Z",
     "iopub.status.idle": "2021-08-29T17:57:03.357816Z",
     "shell.execute_reply": "2021-08-29T17:57:03.356881Z",
     "shell.execute_reply.started": "2021-08-29T17:57:03.297738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU:Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU:{torch.cuda.get_device_name()}\")\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:03.366832Z",
     "iopub.status.busy": "2021-08-29T17:57:03.366476Z",
     "iopub.status.idle": "2021-08-29T17:57:03.380729Z",
     "shell.execute_reply": "2021-08-29T17:57:03.379703Z",
     "shell.execute_reply.started": "2021-08-29T17:57:03.366792Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def remainig_time(tt):\n",
    "    if tt/60 < 1:\n",
    "        return \"{} sec\".format(int(tt))\n",
    "    if tt/60/60 < 1:\n",
    "        return \"{} min\".format(int(tt/60))\n",
    "    if tt/60/60/24 < 1:\n",
    "        mins = tt/60\n",
    "        hrs = mins/60\n",
    "        return \"{:.2f} hrs\".format(hrs)\n",
    "    if tt/60/60/24 > 1:\n",
    "        days = tt/60/60/24\n",
    "        return \"{:.2f} days\".format(days)\n",
    "\n",
    "\n",
    "def save_model(model, optim, loss_train, loss_val, acc_train, acc_val, epoch, model_name, model_path=''):\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optim.state_dict(),\n",
    "        'loss_train': loss_train,\n",
    "        'loss_val': loss_val,\n",
    "        'epoch': epoch,\n",
    "        'acc_train': acc_train,\n",
    "        'acc_val': acc_val,\n",
    "    }, os.path.join(model_path, model_name))\n",
    "\n",
    "\n",
    "def load_model(model_path, device=DEVICE):\n",
    "    return torch.load(model_path, map_location=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:03.386686Z",
     "iopub.status.busy": "2021-08-29T17:57:03.385839Z",
     "iopub.status.idle": "2021-08-29T17:57:03.402821Z",
     "shell.execute_reply": "2021-08-29T17:57:03.401488Z",
     "shell.execute_reply.started": "2021-08-29T17:57:03.386582Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyper Parameters (You can change as you like ... and see how it affects the results)\n",
    "LR = 3e-5\n",
    "BATCH_SIZE = 32\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "IMG_RESIZE = (IMG_HEIGHT, IMG_WIDTH)\n",
    "EPOCHS = 100\n",
    "# Constants\n",
    "NUM_WORKERS = 3 # Based on the \n",
    "NUM_CLASSES = 2\n",
    "CLASSESES = ['NORMAL', 'PNEUMONIA']\n",
    "CHANNELS = 1\n",
    "MIN_ACC = float('-inf')\n",
    "# Data Path\n",
    "DATA_PATH = '../input/chest-xray-pneumonia/chest_xray/'\n",
    "TRAIN_DATA_PATH = os.path.join(DATA_PATH, 'train/')\n",
    "VAL_DATA_PATH = os.path.join(DATA_PATH, 'val/')\n",
    "TEST_DATA_PATH = os.path.join(DATA_PATH, 'test/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Your Pipeline of image transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:03.410077Z",
     "iopub.status.busy": "2021-08-29T17:57:03.409278Z",
     "iopub.status.idle": "2021-08-29T17:57:03.418588Z",
     "shell.execute_reply": "2021-08-29T17:57:03.417578Z",
     "shell.execute_reply.started": "2021-08-29T17:57:03.410024Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transformation\n",
    "TR = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Grayscale(), # 1- convert to GrayScale,\n",
    "    transforms.Resize(IMG_RESIZE), # 2- Resize the Image,\n",
    "    transforms.ToTensor(), # 3- Convert Image data into tensor,\n",
    "    transforms.Normalize(mean=0.5,std=0.5,inplace=True) # 4- Normalize your Image with mean=0.5, std=0.5 \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:03.423621Z",
     "iopub.status.busy": "2021-08-29T17:57:03.419871Z",
     "iopub.status.idle": "2021-08-29T17:57:07.691001Z",
     "shell.execute_reply": "2021-08-29T17:57:07.690138Z",
     "shell.execute_reply.started": "2021-08-29T17:57:03.423468Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data=datasets.ImageFolder(root=TRAIN_DATA_PATH, transform=TR)\n",
    "val_data=datasets.ImageFolder(root=VAL_DATA_PATH, transform=TR)\n",
    "test_data = datasets.ImageFolder(root=TEST_DATA_PATH, transform=TR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:07.692662Z",
     "iopub.status.busy": "2021-08-29T17:57:07.692299Z",
     "iopub.status.idle": "2021-08-29T17:57:07.711150Z",
     "shell.execute_reply": "2021-08-29T17:57:07.710357Z",
     "shell.execute_reply.started": "2021-08-29T17:57:07.692630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.28 ms, sys: 1.2 ms, total: 7.48 ms\n",
      "Wall time: 9.35 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train=pd.DataFrame(train_data.imgs,columns=[\"image_path\", \"label\"])\n",
    "df_val=pd.DataFrame(val_data.imgs,columns=[\"image_path\", \"label\"])\n",
    "df_combined = pd.concat([df_train, df_val],ignore_index=True)\n",
    "## Training And Validation Data Combined with columns: [image_path, label]\n",
    "df_test = pd.DataFrame(test_data.imgs,columns=[\"image_path\", \"label\"])## Testing Data with columns: [image_path, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:07.714643Z",
     "iopub.status.busy": "2021-08-29T17:57:07.714367Z",
     "iopub.status.idle": "2021-08-29T17:57:07.721113Z",
     "shell.execute_reply": "2021-08-29T17:57:07.720120Z",
     "shell.execute_reply.started": "2021-08-29T17:57:07.714618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images in Training set: 5,232\n",
      "Images in Testing set: 624\n"
     ]
    }
   ],
   "source": [
    "print(f\"Images in Training set: {df_combined.shape[0]:,}\")\n",
    "print(f\"Images in Testing set: {df_test.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:07.723718Z",
     "iopub.status.busy": "2021-08-29T17:57:07.723323Z",
     "iopub.status.idle": "2021-08-29T17:57:07.743885Z",
     "shell.execute_reply": "2021-08-29T17:57:07.742967Z",
     "shell.execute_reply.started": "2021-08-29T17:57:07.723681Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4024</th>\n",
       "      <td>../input/chest-xray-pneumonia/chest_xray/train...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3082</th>\n",
       "      <td>../input/chest-xray-pneumonia/chest_xray/train...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>../input/chest-xray-pneumonia/chest_xray/train...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             image_path  label\n",
       "4024  ../input/chest-xray-pneumonia/chest_xray/train...      1\n",
       "3082  ../input/chest-xray-pneumonia/chest_xray/train...      1\n",
       "428   ../input/chest-xray-pneumonia/chest_xray/train...      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:07.745443Z",
     "iopub.status.busy": "2021-08-29T17:57:07.745109Z",
     "iopub.status.idle": "2021-08-29T17:57:07.752061Z",
     "shell.execute_reply": "2021-08-29T17:57:07.751108Z",
     "shell.execute_reply.started": "2021-08-29T17:57:07.745410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../input/chest-xray-pneumonia/chest_xray/train/NORMAL/IM-0115-0001.jpeg'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.image_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:07.754042Z",
     "iopub.status.busy": "2021-08-29T17:57:07.753356Z",
     "iopub.status.idle": "2021-08-29T17:57:07.883597Z",
     "shell.execute_reply": "2021-08-29T17:57:07.882783Z",
     "shell.execute_reply.started": "2021-08-29T17:57:07.754007Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(x=df_train['label'])# Take a look at the Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now given this high bias in our dataset ... we will fix it using 2 tricks ...\n",
    "  - weighted loss   \n",
    "  \n",
    "  so when our model **wrongly predict class 0** (the minority class) ... we **punish him more than** if he predicted class 1 wrong (the majority class)\n",
    "  - Balance the Evaluation dataset  \n",
    "  \n",
    "  we make our evalution dataset has same number of **class 0 and class 1** ... in-order to make the right decision when model has high accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:07.885089Z",
     "iopub.status.busy": "2021-08-29T17:57:07.884738Z",
     "iopub.status.idle": "2021-08-29T17:57:07.894853Z",
     "shell.execute_reply": "2021-08-29T17:57:07.893925Z",
     "shell.execute_reply.started": "2021-08-29T17:57:07.885022Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3883\n",
       "0    1349\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:07.897146Z",
     "iopub.status.busy": "2021-08-29T17:57:07.896416Z",
     "iopub.status.idle": "2021-08-29T17:57:12.144314Z",
     "shell.execute_reply": "2021-08-29T17:57:12.143301Z",
     "shell.execute_reply.started": "2021-08-29T17:57:07.897110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7422, 0.2578], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "## Apply Weighted Loss w.r.t Size of label\n",
    "## So class with low number of images get higher weight\n",
    "## while class with High number of images get lower weight\n",
    "n = [1349 ,3883]\n",
    "weights = [1 - 1349 / sum(n) ,1 - 3883 / sum(n) ]\n",
    "weights = torch.FloatTensor(weights)\n",
    "weight = weights ## Write your code here\n",
    "criterion = nn.NLLLoss(weight= weight).to(DEVICE)\n",
    "# Show the Weights (should be close to this ==> [0.74, 0.25])\n",
    "print(criterion.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:12.146087Z",
     "iopub.status.busy": "2021-08-29T17:57:12.145584Z",
     "iopub.status.idle": "2021-08-29T17:57:12.154383Z",
     "shell.execute_reply": "2021-08-29T17:57:12.153499Z",
     "shell.execute_reply.started": "2021-08-29T17:57:12.146031Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_fn(batches, model, optim, device=DEVICE):\n",
    "    model.train() # set the model mode => training\n",
    "    batch_acc = 0\n",
    "    ep_loss = 0\n",
    "    # Loop through the training batches\n",
    "    for batch in tqdm(batches, total=len(batches), position=0, leave=True):\n",
    "        \n",
    "        imgs, labels = batch# Get Your image and targets from the given batch\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        # Forward Propagation\n",
    "        labels_pred = model(imgs)## Get Your predictions from model\n",
    "        # Calculate Loss\n",
    "        optimizer.zero_grad() ## - Zero your optimizer gradients\n",
    "        loss = criterion(labels_pred,labels)## Get your loss bet. Predictions and Targets\n",
    "        loss.backward()# Backward propagation (Check: https://discuss.pytorch.org/t/what-does-the-backward-function-do/9944)\n",
    "        ## - Calculate loss gradient\n",
    "        optimizer.step()## - Make step with optimizer\n",
    "        ## - Accumulating Loss & Accuracy Across batches\n",
    "        ep_loss += loss.item()\n",
    "        batch_acc += sum(labels == labels_pred.argmax(1)).item()\n",
    "    # Calculate The whole Epoch Accuracy after the batches loop ends\n",
    "    ep_acc = batch_acc / (BATCH_SIZE * len(batches))\n",
    "    ## Return the ep_loss and the ep_acc\n",
    "    return ep_loss, ep_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:12.156034Z",
     "iopub.status.busy": "2021-08-29T17:57:12.155690Z",
     "iopub.status.idle": "2021-08-29T17:57:12.165948Z",
     "shell.execute_reply": "2021-08-29T17:57:12.165076Z",
     "shell.execute_reply.started": "2021-08-29T17:57:12.156000Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval_fn(batches, model, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Calculate the model accuracy & loss on given eval data ... no training is needed here\n",
    "    just prediction and comparing results\n",
    "    \"\"\"\n",
    "    ## Write your code here\n",
    "    batch_acc = 0\n",
    "    ep_loss = 0\n",
    "    # Loop through the training batches\n",
    "    for batch in tqdm(batches, total=len(batches), position=0, leave=True):\n",
    "        \n",
    "        imgs, labels = batch# Get Your image and targets from the given batch\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        # Forward Propagation\n",
    "        labels_pred = model(imgs)## Get Your predictions from model\n",
    "        # Calculate Loss\n",
    "        loss = criterion(labels_pred,labels)## Get your loss bet. Predictions and Targets\n",
    "        ep_loss += loss.item()\n",
    "        batch_acc += sum(labels == labels_pred.argmax(1)).item()\n",
    "    # Calculate The whole Epoch Accuracy after the batches loop ends\n",
    "    ep_acc = batch_acc / (BATCH_SIZE * len(batches))\n",
    "    ## Return the ep_loss and the ep_acc\n",
    "    return ep_loss, ep_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:12.168780Z",
     "iopub.status.busy": "2021-08-29T17:57:12.168427Z",
     "iopub.status.idle": "2021-08-29T17:57:12.178791Z",
     "shell.execute_reply": "2021-08-29T17:57:12.177878Z",
     "shell.execute_reply.started": "2021-08-29T17:57:12.168735Z"
    }
   },
   "outputs": [],
   "source": [
    "def pred_fn(batches, model, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Predict Test batches\n",
    "    Args:\n",
    "        batches (generator): Test Batches\n",
    "        model (model object): Trained Model\n",
    "        device (gpu/cpu device, optional): active device. Defaults to DEVICE.\n",
    "\n",
    "    Returns:\n",
    "        predictions: List of predictions\n",
    "        true_labels: List of true labels\n",
    "    \"\"\"\n",
    "    ## Write your code here\n",
    "    predictions, true_labels = 0,0\n",
    "    for batch in tqdm(batches, total=len(batches), position=0, leave=True):\n",
    "        \n",
    "        imgs, labels = batch# Get Your image and targets from the given batch\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        # Forward Propagation\n",
    "        labels_pred = model(imgs)## Get Your predictions from model\n",
    "        true_labels += labels\n",
    "        predictions += labels_pred\n",
    "    \n",
    "    \n",
    "    return predictions, true_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:12.181106Z",
     "iopub.status.busy": "2021-08-29T17:57:12.179719Z",
     "iopub.status.idle": "2021-08-29T17:57:12.327183Z",
     "shell.execute_reply": "2021-08-29T17:57:12.326299Z",
     "shell.execute_reply.started": "2021-08-29T17:57:12.181042Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:12.328973Z",
     "iopub.status.busy": "2021-08-29T17:57:12.328585Z",
     "iopub.status.idle": "2021-08-29T17:57:12.337448Z",
     "shell.execute_reply": "2021-08-29T17:57:12.336603Z",
     "shell.execute_reply.started": "2021-08-29T17:57:12.328934Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "\n",
    "    def __init__(self, img_paths, targets, transform=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "        self.class_map = {\"NORMAL\" : 0, \"PNEUMONIA\": 1}\n",
    "        self.img_dim = IMG_RESIZE\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths) ## Write your code here\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        target = self.targets[item]\n",
    "        image = cv2.imread(self.img_paths[item])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        image = np.transpose(image,(2,0,1)).astype(np.float32)\n",
    "        \n",
    "        return {\n",
    "            'images': torch.tensor(image) ## Write your code here,\n",
    "            ,'targets': torch.tensor(target) ## Write your code here\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:12.339137Z",
     "iopub.status.busy": "2021-08-29T17:57:12.338787Z",
     "iopub.status.idle": "2021-08-29T17:57:12.720958Z",
     "shell.execute_reply": "2021-08-29T17:57:12.720059Z",
     "shell.execute_reply.started": "2021-08-29T17:57:12.339104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XrayClassifier(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=73728, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class XrayClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # just run the init of parent class (nn.Module)\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) # input is 1 image, 32 output channels, 5x5 kernel / window\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5) # input is 32, bc the first layer output 32. Then we say the output will be 64 channels, 5x5 kernel / window\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "\n",
    "        x = torch.randn(224,224).view(-1,1,224,224)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512) #flattening.\n",
    "        self.fc2 = nn.Linear(512, 2) # 512 in, 2 out bc we're doing 2 classes (dog vs cat).\n",
    "\n",
    "    def convs(self, x):\n",
    "        # max pooling over 2x2\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)  # .view is reshape ... this flattens X before \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x) # bc this is our output layer. No activation here.\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "clf = XrayClassifier()\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test your model with random input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:12.722741Z",
     "iopub.status.busy": "2021-08-29T17:57:12.722264Z",
     "iopub.status.idle": "2021-08-29T17:57:13.154222Z",
     "shell.execute_reply": "2021-08-29T17:57:13.153435Z",
     "shell.execute_reply.started": "2021-08-29T17:57:12.722687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7389, -0.6494]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "CHANNELS = 1\n",
    "BS = 1 # Batch Size\n",
    "ex = torch.rand(BS, CHANNELS, IMG_WIDTH, IMG_HEIGHT)\n",
    "model = XrayClassifier()\n",
    "model.eval()\n",
    "out = model(ex)\n",
    "print(out.shape)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split your Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:13.155840Z",
     "iopub.status.busy": "2021-08-29T17:57:13.155498Z",
     "iopub.status.idle": "2021-08-29T17:57:13.175823Z",
     "shell.execute_reply": "2021-08-29T17:57:13.175018Z",
     "shell.execute_reply.started": "2021-08-29T17:57:13.155802Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sample from positive reviews Same number of negative reviews\n",
    "NEG_N = df_combined['label'].value_counts()[0]\n",
    "df_pos = df_combined[df_combined['label'] == 1]['label'].sample(NEG_N, replace=False)\n",
    "df_balanced = pd.concat([df_combined.iloc[df_pos.index], df_combined[df_combined.label == 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:13.177589Z",
     "iopub.status.busy": "2021-08-29T17:57:13.177032Z",
     "iopub.status.idle": "2021-08-29T17:57:13.287324Z",
     "shell.execute_reply": "2021-08-29T17:57:13.286367Z",
     "shell.execute_reply.started": "2021-08-29T17:57:13.177553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(x=df_balanced['label']) ## Write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:13.291135Z",
     "iopub.status.busy": "2021-08-29T17:57:13.290880Z",
     "iopub.status.idle": "2021-08-29T17:57:13.301719Z",
     "shell.execute_reply": "2021-08-29T17:57:13.300871Z",
     "shell.execute_reply.started": "2021-08-29T17:57:13.291110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4862</th>\n",
       "      <td>../input/chest-xray-pneumonia/chest_xray/train...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3686</th>\n",
       "      <td>../input/chest-xray-pneumonia/chest_xray/train...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>../input/chest-xray-pneumonia/chest_xray/train...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3566</th>\n",
       "      <td>../input/chest-xray-pneumonia/chest_xray/train...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>../input/chest-xray-pneumonia/chest_xray/train...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5219</th>\n",
       "      <td>../input/chest-xray-pneumonia/chest_xray/val/N...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5220</th>\n",
       "      <td>../input/chest-xray-pneumonia/chest_xray/val/N...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221</th>\n",
       "      <td>../input/chest-xray-pneumonia/chest_xray/val/N...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5222</th>\n",
       "      <td>../input/chest-xray-pneumonia/chest_xray/val/N...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5223</th>\n",
       "      <td>../input/chest-xray-pneumonia/chest_xray/val/N...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2698 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             image_path  label\n",
       "4862  ../input/chest-xray-pneumonia/chest_xray/train...      1\n",
       "3686  ../input/chest-xray-pneumonia/chest_xray/train...      1\n",
       "1707  ../input/chest-xray-pneumonia/chest_xray/train...      1\n",
       "3566  ../input/chest-xray-pneumonia/chest_xray/train...      1\n",
       "4605  ../input/chest-xray-pneumonia/chest_xray/train...      1\n",
       "...                                                 ...    ...\n",
       "5219  ../input/chest-xray-pneumonia/chest_xray/val/N...      0\n",
       "5220  ../input/chest-xray-pneumonia/chest_xray/val/N...      0\n",
       "5221  ../input/chest-xray-pneumonia/chest_xray/val/N...      0\n",
       "5222  ../input/chest-xray-pneumonia/chest_xray/val/N...      0\n",
       "5223  ../input/chest-xray-pneumonia/chest_xray/val/N...      0\n",
       "\n",
       "[2698 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:13.304324Z",
     "iopub.status.busy": "2021-08-29T17:57:13.303674Z",
     "iopub.status.idle": "2021-08-29T17:57:13.317406Z",
     "shell.execute_reply": "2021-08-29T17:57:13.316274Z",
     "shell.execute_reply.started": "2021-08-29T17:57:13.304271Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,158 Training imgs\n",
      "540 Validation imgs\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train Test Split with your custome balanced method\n",
    "train_imgs, val_imgs, train_labels, val_labels = train_test_split(df_balanced['image_path'], df_balanced['label'], test_size=0.2, random_state=42,stratify= df_balanced['label'])## Write your code here\n",
    "\n",
    "print(f\"{len(train_imgs):,} Training imgs\")\n",
    "print(f\"{len(val_imgs):,} Validation imgs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Validation labels ... should be equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset instances for Train, Val & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:13.319687Z",
     "iopub.status.busy": "2021-08-29T17:57:13.319318Z",
     "iopub.status.idle": "2021-08-29T17:57:13.329859Z",
     "shell.execute_reply": "2021-08-29T17:57:13.328616Z",
     "shell.execute_reply.started": "2021-08-29T17:57:13.319652Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      ../input/chest-xray-pneumonia/chest_xray/test/...\n",
       "1      ../input/chest-xray-pneumonia/chest_xray/test/...\n",
       "2      ../input/chest-xray-pneumonia/chest_xray/test/...\n",
       "3      ../input/chest-xray-pneumonia/chest_xray/test/...\n",
       "4      ../input/chest-xray-pneumonia/chest_xray/test/...\n",
       "                             ...                        \n",
       "619    ../input/chest-xray-pneumonia/chest_xray/test/...\n",
       "620    ../input/chest-xray-pneumonia/chest_xray/test/...\n",
       "621    ../input/chest-xray-pneumonia/chest_xray/test/...\n",
       "622    ../input/chest-xray-pneumonia/chest_xray/test/...\n",
       "623    ../input/chest-xray-pneumonia/chest_xray/test/...\n",
       "Name: image_path, Length: 624, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:13.331973Z",
     "iopub.status.busy": "2021-08-29T17:57:13.331549Z",
     "iopub.status.idle": "2021-08-29T17:57:13.336892Z",
     "shell.execute_reply": "2021-08-29T17:57:13.335782Z",
     "shell.execute_reply.started": "2021-08-29T17:57:13.331937Z"
    }
   },
   "outputs": [],
   "source": [
    "#self, img_paths, targets, transform=None\n",
    "train_dataset = Dataset(train_imgs,train_labels,transform=TR)## Write your code here\n",
    "val_dataset = Dataset(val_imgs,val_labels,transform=TR)## Write your code here\n",
    "test_dataset = Dataset(df_test.image_path,df_test.label,transform=TR)## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data-Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:13.339067Z",
     "iopub.status.busy": "2021-08-29T17:57:13.338590Z",
     "iopub.status.idle": "2021-08-29T17:57:13.346530Z",
     "shell.execute_reply": "2021-08-29T17:57:13.345680Z",
     "shell.execute_reply.started": "2021-08-29T17:57:13.338951Z"
    }
   },
   "outputs": [],
   "source": [
    "train_batches = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True)## Write your code here\n",
    "val_batches = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle=True)## Write your code here\n",
    "test_batches = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle=True)## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize your model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:13.348434Z",
     "iopub.status.busy": "2021-08-29T17:57:13.347977Z",
     "iopub.status.idle": "2021-08-29T17:57:13.688858Z",
     "shell.execute_reply": "2021-08-29T17:57:13.688003Z",
     "shell.execute_reply.started": "2021-08-29T17:57:13.348397Z"
    }
   },
   "outputs": [],
   "source": [
    "model = XrayClassifier()## Write your code here\n",
    "optim = optim.Adam(model.parameters())## Write your code here # Note: Try with different optimizers and see how it affect the results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:13.690566Z",
     "iopub.status.busy": "2021-08-29T17:57:13.690226Z",
     "iopub.status.idle": "2021-08-29T17:57:13.695638Z",
     "shell.execute_reply": "2021-08-29T17:57:13.694453Z",
     "shell.execute_reply.started": "2021-08-29T17:57:13.690531Z"
    }
   },
   "outputs": [],
   "source": [
    "## Create History For saving your losses and accuraciesXrayClassifier\n",
    "history= {}\n",
    "history['train_loss'] = []\n",
    "history['val_loss'] = []\n",
    "history['train_acc'] = []\n",
    "history['val_acc'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T17:57:13.697618Z",
     "iopub.status.busy": "2021-08-29T17:57:13.697173Z",
     "iopub.status.idle": "2021-08-29T17:57:13.897708Z",
     "shell.execute_reply": "2021-08-29T17:57:13.895294Z",
     "shell.execute_reply.started": "2021-08-29T17:57:13.697581Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/68 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-1f53d26fccdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mep_train_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep_train_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;31m# eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mep_val_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep_val_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-058d5ea7ecc7>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(batches, model, optim, device)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mep_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Loop through the training batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;31m# Get Your image and targets from the given batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-2d73024df5e4>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         return {\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "        s = time()\n",
    "        # train\n",
    "        ep_train_loss, ep_train_acc = train_fn(train_batches, model, optim)\n",
    "        # eval\n",
    "        ep_val_loss, ep_val_acc = eval_fn(val_batches, model)\n",
    "        e = time()\n",
    "\n",
    "        epoch_t = remainig_time(e - s)\n",
    "        whole_time = remainig_time((e - s) * (EPOCHS - epoch))\n",
    "        print(f\"\\nEpoch:{epoch}/{EPOCHS}---Loss-train:{ep_train_loss:.4f}---Loss-Val: {ep_val_loss:.4f}---Acc-Train:{(ep_train_acc*100):.2f}%---Acc-Val: {(ep_val_acc*100):.2f}%---Acc-Test: {(ep_test_acc*100):.2f}---%epoch elapsed:{epoch_t}---Remaining:{whole_time}\")\n",
    "        \n",
    "        ## Write your code here ## append the training loss\n",
    "        ## Write your code here ## append the validation loss\n",
    "        ## Write your code here ## append the training acc\n",
    "        ## Write your code here ## append the validation acc\n",
    "\n",
    "        if ep_val_acc > MIN_ACC:\n",
    "            print(\"Saving Model ...\")\n",
    "            model_name = f'Xray_ep_{epoch}_acc_{(ep_test_acc*100):.3f}_.pth'\n",
    "            MIN_ACC = ep_test_acc\n",
    "            # Save Your model Checkpoint\n",
    "            ## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-29T17:57:13.898424Z",
     "iopub.status.idle": "2021-08-29T17:57:13.898804Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = '' # Get your model path\n",
    "checkpoint = load_model(MODEL_PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict']) # Just loading the model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-29T17:57:13.899903Z",
     "iopub.status.idle": "2021-08-29T17:57:13.900523Z"
    }
   },
   "outputs": [],
   "source": [
    "preds, labels = pred_fn(test_batches, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-29T17:57:13.901520Z",
     "iopub.status.idle": "2021-08-29T17:57:13.902154Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {(np.array(preds) == np.array(labels)).mean()*100:.1f}% On Test Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-29T17:57:13.903292Z",
     "iopub.status.idle": "2021-08-29T17:57:13.903896Z"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(labels, preds, target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a confusion matrix and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-29T17:57:13.904945Z",
     "iopub.status.idle": "2021-08-29T17:57:13.905570Z"
    }
   },
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Work ... 💪💪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're able to get and start applying your various types of ***DL approches*** and ***compete with many Kagglers***\n",
    "There exist huge amount of images data out there ... that you're now able to give it a try and apply your own model on ... Good Start 👍👍😊"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
